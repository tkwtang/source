{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# miniconda3/bin/pythonscreen -r 56633"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autotime\n",
    "import pandas as pd\n",
    "import NAND_PARAMETERS\n",
    "import json, importlib, os\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from test_NAND_platform_helper_function import loadDataFrame, getDataByID, getSimulationID, getDataByComment, getDataByField\n",
    "from test_NAND_platform_helper_function import showGraph, showFidelity, getSimulationWorkStatistics, getFidelityTimeGraph, drawFidelityBarChart\n",
    "from test_NAND_platform_helper_function import get_correct_and_wrong_number, pick_out_wrong_item, report_data\n",
    "\n",
    "rc_dict = {'font.size':16, 'axes.labelsize':'large', 'ytick.right':False,'legend.loc':'upper right', 'legend.fontsize':'xx-small', 'figure.autolayout':True, 'figure.figsize': (10,10), 'mathtext.fontset':'stix', 'font.family':'STIXGeneral'}\n",
    "\n",
    "\n",
    "mpl.rcParams.update(rc_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# integrated_data_into_gallery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# database_array = [\"gallery.json\", \"gallery_2025_08_30.json\"]\n",
    "\n",
    "# sim_id = \"c3ed1db1cdbec947bbfb2f67c0fab51fe198de8879866e6b6f306e3f298fd4e6\"\n",
    "# for database in database_array:\n",
    "#     print(f\"seaching {database}\")\n",
    "#     try:\n",
    "#         df = loadDataFrame(gallery_path = f\"coupled_flux_qubit_protocol/{database}\")\n",
    "#         target = getDataByID(df=df, sim_id=sim_id).head(1)\n",
    "#         if len(target) > 0:\n",
    "#             break\n",
    "#     except: \n",
    "#         pass\n",
    "        \n",
    "\n",
    "# print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(NAND_PARAMETERS.GALLERY_JSON_FILE)) as rf:\n",
    "    jsonData = json.load(rf)\n",
    "    # jsonData += new_data_array\n",
    "    # with open(os.path.join(gallery_base_path, \"test_database.json\"), \"w+\") as wf:\n",
    "    #     json.dump(jsonData, wf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## delete before integrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_waiting_to_be_integrated = [os.path.join(NAND_PARAMETERS.GALLERY_JSON_FOLDER, x) for x in os.listdir(NAND_PARAMETERS.GALLERY_JSON_FOLDER) if \"_waiting_to_be_integrated_to_gallery\" in x]\n",
    "new_data_array = []\n",
    "for filePath in file_waiting_to_be_integrated:\n",
    "    with open(filePath) as f:\n",
    "        try:\n",
    "            new_data_array.append(json.load(f))\n",
    "        except:\n",
    "            pass\n",
    "print(len(file_waiting_to_be_integrated))\n",
    "\n",
    "os.system(f\"cp {NAND_PARAMETERS.GALLERY_JSON_FILE} {NAND_PARAMETERS.GALLERY_JSON_BACKUP_FILE}\")\n",
    "\n",
    "with open(NAND_PARAMETERS.GALLERY_JSON_FILE) as rf:\n",
    "    jsonData = json.load(rf)\n",
    "    jsonData += new_data_array\n",
    "    with open(NAND_PARAMETERS.GALLERY_JSON_FILE, \"w+\") as wf:\n",
    "        json.dump(jsonData, wf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = [os.system(f\"rm {file_path}\") for file_path in file_waiting_to_be_integrated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "# check initial states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_1 = 1.5\n",
    "# initial_state_array = f\"NAND_test/saved_init_state/init_state_database_2/T_4.2K_N_1000_beta_{beta_1}\"\n",
    "initial_state_array = f\"saved_init_state/init_state_database_2/T_4.2K_N_1000_beta_{beta_1}\"\n",
    "\n",
    "print(len(os.listdir(initial_state_array)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "# Show a group of same simulation result\n",
    "- this is for checking the work done and error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = loadDataFrame()\n",
    "\n",
    "data_group = [\"Experiment 1 (2025/6/23)\", \"Experiment 5 (2025/6/24)\", \"Experiment 1 (2025/6/25)\", \"Experiment 4 (2025/6/25)\"]\n",
    "\n",
    "\"\"\"Finished\"\"\"\n",
    "# target = getDataByComment(df,  \"Experiment 1 (2025-07-05)\") # adiabatic 1.35\n",
    "\n",
    "# target = getDataByComment(df,  \"Experiment 4 (2025/6/25)\")\n",
    "# target = getDataByComment(df,  \"Experiment 3 (2025/6/27)\")\n",
    "# target = getDataByComment(df,  \"Experiment 2 (2025-07-01)\")\n",
    "target = getDataByComment(df,  \"Experiment 1 (2025-07-02)\")\n",
    "# target = getDataByComment(df,  \"Experiment 1 (2025-07-03)\")\n",
    "\n",
    "# target = getDataByComment(df,  \"Experiment 1 (2025-07-08)\") # adiabatic 1.5\n",
    "# target = getDataByComment(df,  \"Experiment 1 (2025-07-05)\") # adiabatic 1.35\n",
    "# target = getDataByComment(df,  \"Experiment 1 (2025-07-09)\") # adiabatic 2.3 with different phi_1xdc\n",
    "# target = getDataByComment(df,  \"Experiment 4 (2025-07-09)\") # harmonic 1.4\n",
    "\n",
    "# target = getDataByComment(df,  \"Experiment 1 (2025-07-15)\") \n",
    "# target = getDataByComment(df,  \"Experiment 2 (2025-07-15)\") \n",
    "# target = getDataByComment(df,  \"Experiment 1 (2025-07-17)\")\n",
    "# target = getDataByComment(df,  \"Experiment 1 (2025-07-16)\")\n",
    "\n",
    "# target = getDataByComment(df,  \"Experiment 4 (2025-07-20)\") \n",
    "# target = getDataByComment(df,  \"Experiment 5 (2025-07-20)\")  # phi_1xdc = {0.76, 1.1, 0.89, 1.03}\n",
    "\n",
    "# target = getDataByComment(df,  \"Experiment 1 (2025-07-21)\") \n",
    "# target = getDataByComment(df,  \"Experiment 2 (2025-07-29)\") # harmonic 1.35, gamma = 9, harmonic\n",
    "\n",
    "# target = getDataByComment(df,  \"Experiment 2 (2025-07-12)\") # harmonic 1.35, gamma = 9\n",
    "# target = getDataByComment(df,  \"Experiment 1 (2025-08-19)\") # harmonic 2.3 -> 1.35 \n",
    "\n",
    "target = getDataByID(df, \"185ebdc3f664665cc4aad5e273bc1846e7c1d8650bf89fce7dd097b280402655\")\n",
    "\n",
    "# 1.99, 2.04, 2.1, 1.9000000000000001, 1.945\n",
    "# 1.03\n",
    "# beta = 2.3: [1.945, 1.985, 2.04, 2.10]\n",
    "filter_condition_1 = np.array([x[0]['phi_1xdc'] for x in target['protocol_list_item'].values]) == 1.9000000000000001\n",
    "filter_condition_2 = np.array([x[0]['duration'] for x in target['protocol_list_item'].values]) == 50\n",
    "# target = target[filter_condition_1]\n",
    "\n",
    "\n",
    "# beta = 1.35: [0.76, 0.89, 1.03, 1.1]\n",
    "# filter_condition_1 = np.array([x[0]['phi_1xdc'] for x in target['protocol_list_item'].values]) == 1.1\n",
    "# filter_condition_2 = np.array([x[0]['duration'] for x in target['protocol_list_item'].values]) == 25\n",
    "# target = target[np.logical_and(filter_condition_1, filter_condition_2)]\n",
    "# print(len(target))\n",
    "# target = target[filter_condition]\n",
    "# target = target.tail(2)\n",
    "# target = getDataByID(df, \"025f7a325acf562383d7181a0906450e01a9576d1494655024a0969ba6bde877\")\n",
    "\n",
    "# 0: \"T\", 1: dt, 2: N, 3: duration, 4: C, 5: L, 6: gamma\n",
    "print(len(target))\n",
    "print(f\"phi_1xdc = {set([x[0]['phi_1xdc'] for x in target['protocol_list_item'].values])}\")\n",
    "print(f\"duration = {set([x[0]['duration'] for x in target['protocol_list_item'].values])}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import test_NAND_platform_helper_function\n",
    "importlib.reload(test_NAND_platform_helper_function)\n",
    "test_NAND_platform_helper_function.report_data(target, showGraph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import test_NAND_platform_helper_function\n",
    "importlib.reload(test_NAND_platform_helper_function)\n",
    "\n",
    "\n",
    "df = loadDataFrame()\n",
    "name = \"Experiment 2 (2025-07-29)\" # harmonic 2.3 -> 1.35 \n",
    "\n",
    "name = \"Experiment 1 (2025-07-10)\" # this one can be used to create Figure 8\n",
    "# name = \"Experiment 2 (2025-08-19)\" # harmonic 2.3 -> 1.35, to test if the two are the same\n",
    "\n",
    "\n",
    "# name = \"Experiment 5 (2025-08-23)\" # harmonic 1.35, t = 6, phi_1xdc = 0.8\n",
    "\n",
    "# name = \"Experiment 9 (2025-08-24)\" # \n",
    "\n",
    "\n",
    "\n",
    "target = getDataByComment(df, name) \n",
    "\n",
    "\n",
    "print(len(target))\n",
    "test_NAND_platform_helper_function.report_data(target, showGraph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Experiment 1 (2025-07-27)\"\n",
    "target = getDataByComment(df,  name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = loadDataFrame()\n",
    "# target = getDataByComment(df,  \"Experiment 4 (2025-07-20)\") \n",
    "# target = getDataByComment(df,  \"Experiment 5 (2025-07-20)\") \n",
    "# target = getDataByComment(df,  \"Experiment 1 (2025-07-21)\") \n",
    "\n",
    "# beta = 2.3: \n",
    "# simulation_result_beta_2_3_gamma_16\n",
    "name = \"Experiment 2 (2025-07-21)\" # t = 150\n",
    "# name = \"Experiment 1 (2025-07-23)\" # t = 75\n",
    "\n",
    "# simulation_result_beta_2_3_gamma_9\n",
    "# name = \"Experiment 1 (2025-07-28)\" # t = 150\n",
    "# name = \"Experiment 2 (2025-07-12)\" #\n",
    "\n",
    "phi_1xdc_array = [1.9000000000000001, 1.94, 1.985, 2.04, 2.10]\n",
    "\n",
    "# phi_1xdc_array = [1.9000000000000001, 1.945, 1.99, 2.04, 2.10]\n",
    "\n",
    "\n",
    "target = getDataByComment(df,  name)\n",
    "\n",
    "for _phi_1xdc in phi_1xdc_array:\n",
    "\n",
    "    filter_condition_1 = np.array([x[0]['phi_1xdc'] for x in target['protocol_list_item'].values]) == _phi_1xdc\n",
    "    # filter_condition_2 = np.array([x[0]['duration'] for x in target['protocol_list_item'].values]) == _t\n",
    "    # _target = target[np.logical_and(filter_condition_1, filter_condition_2)]\n",
    "    _target = target[filter_condition_1]\n",
    "    try:\n",
    "        test_NAND_platform_helper_function.report_data(_target, preText = f\"phi_1xdc = {_phi_1xdc}\")\n",
    "    except:\n",
    "        print(f\"no data for t = , phi_1xdc = {_phi_1xdc}\")\n",
    "        print(\"-\" * 20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = loadDataFrame()\n",
    "# beta = 1.35: \n",
    "\n",
    "# adiabatic\n",
    "\n",
    "\n",
    "name = \"Experiment 4 (2025-07-20)\" # t = 150, beta = 1.35, gamma = 16\n",
    "# name = \"Experiment 5 (2025-07-20)\" # t = 75, beta = 1.35, gamma = 16\n",
    "# name = \"Experiment 2 (2025-07-28)\"\n",
    "# name = \"Experiment 1 (2025-07-27)\" \n",
    "\n",
    "# name = \"Experiment 3 (2025-07-29)\" # beta = 1.35, gamma = 9, t= 42\n",
    "# name = \"Experiment 1 (2025-07-29)\" # beta = 1.35, gamma = 9, t= 75 (multiple phi_1xdc)\n",
    "# name = \"Experiment 1 (2025-07-30)\" # beta = 1.35, gamma = 9, t= 150\n",
    "\n",
    "# name = \"Experiment 4 (2025-07-29)\" # beta = 1.35, gamma = 16, t= 42\n",
    "# name = \"Experiment 2 (2025-07-30)\" # beta = 1.35, gamma = 16, t= 150\n",
    "\n",
    "\n",
    "# Experiment 2 (2025-07-30)\n",
    "phi_1xdc_array = [0.76, 0.89, 1.03, 1.1]\n",
    "\n",
    "\n",
    "target = getDataByComment(df,  name)\n",
    "\n",
    "for _phi_1xdc in phi_1xdc_array:\n",
    "\n",
    "    filter_condition_1 = np.array([x[0]['phi_1xdc'] for x in target['protocol_list_item'].values]) == _phi_1xdc\n",
    "    # filter_condition_2 = np.array([x[0]['duration'] for x in target['protocol_list_item'].values]) == _t\n",
    "    # _target = target[np.logical_and(filter_condition_1, filter_condition_2)]\n",
    "    _target = target[filter_condition_1]\n",
    "    try:\n",
    "        test_NAND_platform_helper_function.report_data(_target, preText = f\"phi_1xdc = {_phi_1xdc}\")\n",
    "    except:\n",
    "        print(f\"no data for t = , phi_1xdc = {_phi_1xdc}\")\n",
    "        print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    export_simulation_json(target, \"Experiment 4 (2025-07-29)_t_42.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = loadDataFrame()\n",
    "# beta = 1.35: \n",
    "\n",
    "# adiabatic\n",
    "\n",
    "\n",
    "name = \"Experiment 1 (2025-08-25)\" # speed test for beta = 1.35, gamma = 9, phi_1xdc = 0.8\n",
    "name = \"Experiment 3 (2025-08-25)\" # speed test for beta = 1.35, gamma = 9, phi_1xdc = 1.1\n",
    "\n",
    "# Experiment 2 (2025-07-30)\n",
    "params_array = [(4, 0), (4.5, 0), (5, 0), (5.5, 0), (6, 0)]\n",
    "\n",
    "target = getDataByComment(df,  name)\n",
    "\n",
    "for t_2, t_2_5 in params_array:\n",
    "\n",
    "    filter_condition_1 = np.array([x[1]['duration'] for x in target['protocol_list_item'].values]) == t_2\n",
    "    # filter_condition_2 = np.array([x[0]['duration'] for x in target['protocol_list_item'].values]) == _t\n",
    "    # _target = target[np.logical_and(filter_condition_1, filter_condition_2)]\n",
    "    _target = target[filter_condition_1]\n",
    "    try:\n",
    "        report_data(_target, preText = f\"phi_1xdc = {_phi_1xdc}\")\n",
    "    except:\n",
    "        print(f\"no data for t = , phi_1xdc = {_phi_1xdc}\")\n",
    "        print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = loadDataFrame()\n",
    "\n",
    "name = \"Experiment 4 (2025-08-25)\" # speed test for beta = 1.35, gamma = 9, phi_1xdc = 1.1, with params_array = [(4, 1), (4.5, 1), (5, 1), (5.5, 1), (6, 0)]\n",
    "params_array = [(4, 1), (4.5, 1), (5, 1), (5.5, 1), (6, 0)]\n",
    "\n",
    "\n",
    "target = getDataByComment(df,  name)\n",
    "\n",
    "for t_2, t_2_5 in params_array:\n",
    "\n",
    "    filter_condition_1 = np.array([x[1]['duration'] for x in target['protocol_list_item'].values]) == t_2\n",
    "    # filter_condition_2 = np.array([x[0]['duration'] for x in target['protocol_list_item'].values]) == _t\n",
    "    # _target = target[np.logical_and(filter_condition_1, filter_condition_2)]\n",
    "    _target = target[filter_condition_1]\n",
    "    try:\n",
    "        report_data(_target, preText = f\"phi_1xdc = {_phi_1xdc}\")\n",
    "    except:\n",
    "        print(f\"no data for t = , phi_1xdc = {_phi_1xdc}\")\n",
    "        print(\"-\" * 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## use speed as a trade off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import test_NAND_platform_helper_function\n",
    "importlib.reload(test_NAND_platform_helper_function)\n",
    "\n",
    "df = loadDataFrame()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# speed test for beta = 1.35, gamma = 9, this one has no error in flipping pair, but some in the erasure pair\n",
    "# name = \"Experiment 1 (2025-07-03)\"\n",
    "\n",
    "# name = \"Experiment 2 (2025-09-07)\"\n",
    "\n",
    "name = \"Experiment 1 (2025-08-29)\" # harmonic oscillator, \n",
    "name = \"Experiment 4 (2025-09-01)\" # harmonic oscillator, \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# name = \"Experiment 2 (2025-09-07)\" # harmonic oscillator, \n",
    "# name = \"Experiment 4 (2025-09-08)\" # harmonic oscillator, \n",
    "# name = \"Experiment 3 (2025-09-09)\" # harmonic oscillator\n",
    "# name = \"Experiment 4 (2025-09-09)\" # harmonic oscillator\n",
    "\n",
    "name = \"Experiment 1 (2025-09-12)\" # NAND + EF with 16kBT (slow)\n",
    "\n",
    "name = \"Experiment 9 (2025-09-05)\" # NAND + EF with 30kBT (fast), \n",
    "\n",
    "\n",
    "# name = \"Experiment 1 (2025-09-15)\" # NAND + CE\n",
    "# name = \"Experiment 1 (2025-07-10)\"\n",
    "\n",
    "# name = \"Experiment 2 (2025-07-29)\" # harmonic oscillator, 16kBT\n",
    "showGraph = False\n",
    "target = getDataByComment(df,  name)\n",
    "test_NAND_platform_helper_function.report_data(target, showGraph=showGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for sim_id in list(target['simulation_id'])[0:10]:\n",
    "    if os.path.isfile(f\"coupled_flux_qubit_protocol/coupled_flux_qubit_data_gallery_temp/{sim_id}_work_distribution.npy'\"):\n",
    "        print(\"no file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "target.head(1)[\"simulation_data\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_sid = f\"{target['simulation_id'].values[0]}\"\n",
    "initial_index = np.load(f\"coupled_flux_qubit_protocol/coupled_flux_qubit_data_gallery/{target_sid}_initial_index.npy\", allow_pickle=True)\n",
    "final_state = np.load(f\"coupled_flux_qubit_protocol/coupled_flux_qubit_data_gallery/{target_sid}_final_state.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "## export json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def export_simulation_json(target_sid, export_name):\n",
    "    with open(f\"NAND_test/{export_name}\", \"w\") as f:\n",
    "        target = getDataByID(df, target_sid)\n",
    "        json.dump(target.head(1).to_dict('records')[0], f, indent=4)\n",
    "        print(export_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_sid = \"6c9f1e7edf29eb0cb203c83857f89b0449e19a926fb7b3a8a3c5764e82529e83\"\n",
    "export_simulation_json(target_sid, \"json_input_folder/Experiment 1 (2025-09-12).json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_sid = \"6c9f1e7edf29eb0cb203c83857f89b0449e19a926fb7b3a8a3c5764e82529e83\"\n",
    "export_simulation_json(target_sid, \"json_input_folder/Experiment 1 (2025-09-12).json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_dummy_by_sid(sid, N = 200):\n",
    "    print(f\"bash run_N_time_dummy.sh -s {sid} -n {N}\")\n",
    "\n",
    "def run_dummy_by_json(json_file, N = 200):\n",
    "    print(f\"bash run_N_time_dummy_json_input.sh -s '{json_file}' -n {N}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "## export parent sim id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"NAND_test/placeholder/thermalize_id_for_Experiment 1 (2025-08-27).txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(target['simulation_id'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_data_group(experiments_to_report):\n",
    "    for x in experiments_to_report:\n",
    "        target = getDataByComment(df, x)\n",
    "        parameter_array = [\"T\", \"dt\", \"N\", \"duration\", \"C\", \"L\", \"gamma\"]\n",
    "        sim_id_array = list(target['simulation_id'].values)\n",
    "        statistic_data_array = [getSimulationWorkStatistics(df, _sim_id) for _sim_id in sim_id_array]\n",
    "        target.tail(1).columns\n",
    "        \n",
    "        work_dist_array = [_data['work_distribution_data'] for _data in statistic_data_array]\n",
    "        mean_work_array = [_data['mean_W'] for _data in statistic_data_array]\n",
    "        mean_work_ste   = np.array([_data['mean_W_error'] for _data in statistic_data_array])\n",
    "\n",
    "        \n",
    "        # work_dist_array  = np.repeat(work_dist_array, 2)\n",
    "        # work_stat_array = np.array([_data['work_statistic_data'] for _data in statistic_data_array])\n",
    "        N = len(work_dist_array)\n",
    "\n",
    "        error_rate_array = np.array([_data['error_rate_array'] for _data in statistic_data_array])\n",
    "        wrong_info_array = [pick_out_wrong_item(item) for item in error_rate_array]\n",
    "        correct_and_wrong = np.sum(np.array([get_correct_and_wrong_number(item) for item in error_rate_array]), axis = 0)\n",
    "        total_error_rate = correct_and_wrong[1] / (correct_and_wrong[0] + correct_and_wrong[1])\n",
    "        error_detail = np.sum(np.vstack(wrong_info_array), axis = 0)\n",
    "        N = np.sum(correct_and_wrong)\n",
    "        \n",
    "        joint_work_dist = np.concatenate(work_dist_array)\n",
    "        mean_joint_work_dist = np.mean(joint_work_dist)\n",
    "        std_error_joint_work_dist = np.std(joint_work_dist)/np.sqrt(len(joint_work_dist))* 3\n",
    "\n",
    "        print(x)\n",
    "        print(f\"N = {len(joint_work_dist):,}\")\n",
    "        print(f\"{mean_joint_work_dist:.3g}± { std_error_joint_work_dist:.3g}\")\n",
    "        print(f\"total number = {N:,}, correct = {correct_and_wrong[0]:,}, wrong = {correct_and_wrong[1]:,}\")\n",
    "        print(f\"error rate = {total_error_rate*100:.3g}%\")\n",
    "        print(f\"error for each category: {error_detail}\")\n",
    "        print(\"-\" * 10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "experiments_to_report = [\"Experiment 1 (2025-07-02)\", \"Experiment 1 (2025-07-03)\", \"Experiment 4 (2025-07-09)\"]\n",
    "report_data_group(experiments_to_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSimulationWorkStatistics2(target, sim_id, folderPath = \"coupled_flux_qubit_protocol/coupled_flux_qubit_data_gallery\"):\n",
    "    \"\"\"\n",
    "    'params', 'initial_parameter_dict', 'protocol_list_item',\n",
    "       'simulation_data', 'circuit_parameters', 'sim_params', 'jarzynski_term',\n",
    "       'mean_work', 'fidelity', 'keyStep_work_statistic',\n",
    "       'fidleity_time_array', 'target_step_index_info', 'comment', 'script',\n",
    "       'simulation_id'\n",
    "    \"\"\"\n",
    "    dt = list(target['params'])[0][\"dt\"]\n",
    "    N =  list(target['params'])[0][\"N\"]\n",
    "    \n",
    "    \n",
    "    work_distribution_data = np.load(f\"{folderPath}/{sim_id}_work_distribution.npy\")\n",
    "    work_statistic_data = np.load(f\"{folderPath}/{sim_id}_work_statistic.npy\")\n",
    "    fidelity_time_array = np.load(f\"{folderPath}/{sim_id}_fidelity_time_array.npy\")\n",
    "    jarzyn_term = np.mean(np.exp(-work_distribution_data))\n",
    "    jarzyn_term_error = 3 * np.std(np.exp(-work_distribution_data)) / np.sqrt(N)\n",
    "    keyStep_work_statistic = target['keyStep_work_statistic'].values[0]\n",
    "    error_rate_array = target['error_rate_array'].values[0]\n",
    "    target_step_index_info = list(target['target_step_index_info'])[0]\n",
    "    target_step_index = list(range(target_step_index_info['start'], target_step_index_info['end']+1, target_step_index_info['step']))\n",
    "\n",
    "    return {\n",
    "        \"work_distribution_data\": work_distribution_data,\n",
    "        \"work_statistic_data\": work_statistic_data,\n",
    "        \"fidelity_time_array\": fidelity_time_array,\n",
    "        \"target_time_index\": target_step_index,\n",
    "        \"error_rate_array\": error_rate_array,\n",
    "        \"keyStep_work_statistic\": keyStep_work_statistic, \n",
    "        \"N\": N, \"dt\": dt, \"mean_W\": np.mean(work_distribution_data), \"mean_W_error\": np.std(work_distribution_data) / np.sqrt(len(work_distribution_data)),\n",
    "        \"jarzyn_term\": jarzyn_term, \"jarzyn_term_error\": jarzyn_term_error\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = target['initial_parameter_dict'].values[0]['beta_1']\n",
    "gamma = target['initial_parameter_dict'].values[0]['gamma_1']\n",
    "protocol_list = list(target['protocol_list_item'])[0]\n",
    "sim_id_array = list(target['simulation_id'].values)\n",
    "statistic_data_array = [getSimulationWorkStatistics2(target, _sim_id) for _sim_id in sim_id_array]\n",
    "\n",
    "\n",
    "# work_analysis\n",
    "work_dist_array = [_data['work_distribution_data'] for _data in statistic_data_array]\n",
    "mean_work_array = [_data['mean_W'] for _data in statistic_data_array]\n",
    "mean_work_ste   = np.array([_data['mean_W_error'] for _data in statistic_data_array])\n",
    "\n",
    "# work_dist_array  = np.repeat(work_dist_array, 2)\n",
    "work_stat_array = np.array([_data['work_statistic_data'] for _data in statistic_data_array])\n",
    "N = len(work_dist_array)\n",
    "index = np.mean([np.sum(x['protocol_time_array']) for x in target['params']])\n",
    "\n",
    "joint_work_dist = np.concatenate(work_dist_array)\n",
    "mean_joint_work_dist = np.mean(joint_work_dist)\n",
    "std_error_joint_work_dist = np.std(joint_work_dist)/np.sqrt(len(joint_work_dist))* 3\n",
    "\n",
    "\n",
    "\"\"\"error analysis\"\"\"\n",
    "correct_number = 0\n",
    "wrong_number = 0\n",
    "total_correct_particle = np.array([0, 0, 0, 0])\n",
    "total_wrong_particle = np.array([0, 0, 0, 0])\n",
    "for item in target.error_rate_array.values:\n",
    "    \n",
    "    for index, particle_data in enumerate(item):\n",
    "        correct_number += particle_data['correct_number']\n",
    "        wrong_number   += particle_data['wrong_number']\n",
    "        total_correct_particle[index] += particle_data['correct_number']\n",
    "        total_wrong_particle[index] += particle_data['wrong_number']\n",
    "\n",
    "        # wrong_particle = np.array([ if k != particle_data['correct_number'] else 0 for k in particle_data['final'] ])\n",
    "\n",
    "print(correct_number, wrong_number, f\"{wrong_number/(correct_number + wrong_number)}\")\n",
    "\n",
    "\n",
    "\n",
    "error_rate_array = np.array([_data['error_rate_array'] for _data in statistic_data_array])\n",
    "wrong_info_array = [pick_out_wrong_item(item) for item in error_rate_array]\n",
    "correct_and_wrong = np.sum(np.array([get_correct_and_wrong_number(item) for item in error_rate_array]), axis = 0)\n",
    "total_error_rate = correct_and_wrong[1] / (correct_and_wrong[0] + correct_and_wrong[1])\n",
    "error_detail = np.sum(np.vstack(wrong_info_array), axis = 0)\n",
    "N = np.sum(correct_and_wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "# thermalize_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = loadDataFrame()\n",
    "target_sid = \"185ebdc3f664665cc4aad5e273bc1846e7c1d8650bf89fce7dd097b280402655\"\n",
    "target = getDataByID(df,  target_sid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = os.listdir(\"coupled_flux_qubit_protocol/coupled_flux_qubit_data_gallery\")\n",
    "print(s[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_item_simulation_data = target['simulation_data'].values.item()\n",
    "parent_simulation_id = target_item_simulation_data[\"parent_simulation_id\"]\n",
    "\n",
    "target_initial_index = np.load(f\"coupled_flux_qubit_protocol/coupled_flux_qubit_data_gallery/{parent_simulation_id}_initial_index.npy\", allow_pickle=True).item()\n",
    "\n",
    "before_thermalized_state = np.load(f\"coupled_flux_qubit_protocol/coupled_flux_qubit_data_gallery/{parent_simulation_id}_final_state.npy\")\n",
    "before_thermalized_state = before_thermalized_state[:, (0, 1), ...]\n",
    "\n",
    "thermalized_state = np.load(f\"coupled_flux_qubit_protocol/coupled_flux_qubit_data_gallery/{target_sid}_final_state.npy\")\n",
    "thermalized_state = thermalized_state[:, (0, 1), ...]\n",
    "\n",
    "\n",
    "final_KE = target['final_KE']\n",
    "# init_state_used = np.load(f\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for key, p_index in target_initial_index.items():\n",
    "    print(p_index)\n",
    "    print(key)\n",
    "\n",
    "    plt.scatter(thermalized_state[p_index, 0, 0], thermalized_state[p_index, 1, 0], color = pColor[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import NAND_PARAMETERS\n",
    "import edward_tools.couple_flux_qubit_metrics as couple_flux_qubit_metrics\n",
    "importlib.reload(couple_flux_qubit_metrics)\n",
    "importlib.reload(NAND_PARAMETERS)\n",
    "\n",
    "couple_flux_qubit_metrics.fidelityEvaluation(before_thermalized_state, thermalized_state, NAND_PARAMETERS.mapping_state_1_to_state_2_erasure_flip, initial_index=target_initial_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "## change comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "backup_database = False\n",
    "if backup_database:\n",
    "    os.system(\"cp coupled_flux_qubit_protocol/coupled_flux_qubit_data_gallery/gallery.json coupled_flux_qubit_protocol/coupled_flux_qubit_data_gallery/gallery_backup.json\")\n",
    "    \n",
    "database_path = \"coupled_flux_qubit_protocol/coupled_flux_qubit_data_gallery/gallery.json\"\n",
    "df = pd.read_json(database_path)\n",
    "df['comment'] = [item['comment'] for item in df[\"params\"]]\n",
    "df[\"simulation_id\"] = [item[\"simulation_id\"] for item in df[\"simulation_data\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def editComment():\n",
    "    df = loadDataFrame()\n",
    "    target = getDataByComment(df,  \"Experiment 3 (2025-1-31)\")\n",
    "    target_new_2 = np.array([np.sum(x['protocol_time_array']) for x in df['params']] ) == 800\n",
    "    \n",
    "    \n",
    "    \n",
    "    replaced_params = target.head(1)['params'].values[0]\n",
    "    \n",
    "    index_new = df['comment'].values == \"Experiment 1 (2025-1-31): To study the trade-off between speed and work done, and also speed and fidelity CE_t_factor = 5.0, dt = 1/500, multiple 100 times\"\n",
    "    index_new_2 = np.array([np.sum(x['protocol_time_array']) for x in df['params']] ) == 800\n",
    "    \n",
    "    combined_index = np.logical_and(index_new,  index_new_2)\n",
    "    \n",
    "    replacement_column = pd.Series([replaced_params] * np.sum(combined_index))\n",
    "    \n",
    "    df.loc[combined_index, 'params'] = replacement_column\n",
    "    df = df.drop(['comment', 'simulation_id'], axis = 1)\n",
    "    df.to_json(\"test_database.json\", orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_comment = \"Experiment 3 (2025-1-31)\"\n",
    "replacement_comment = \"Experiment 3 (2025-1-30)\"\n",
    "\n",
    "target = df[df['comment'].str.contains(target_comment, regex = False)]\n",
    "target_index = np.array([np.sum(x['protocol_time_array']) for x in target['params']]) == 800\n",
    "replaced_params = target[target_index].head(1)['params'].values[0]\n",
    "replaced_params['comment'] = replacement_comment\n",
    "\n",
    "index_new = df['comment'].str.contains(target_comment, regex = False)\n",
    "index_new_2 = np.array([np.sum(x['protocol_time_array']) for x in df['params']] ) == 800\n",
    "combined_index = np.logical_and(index_new,  index_new_2)\n",
    "\n",
    "\n",
    "replacement_column = pd.Series([replaced_params] * np.sum(combined_index))\n",
    "replacement_column.index = combined_index[combined_index == True].index\n",
    "df.loc[combined_index, 'params'] = replacement_column\n",
    "\n",
    "df = df.drop(['comment', 'simulation_id'], axis = 1)\n",
    "# df.to_json(database_path, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.array([np.sum(x['protocol_time_array']) for x in target['params']] ) == 800\n",
    "selected_target = target[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "# repair database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "repair = False\n",
    "\n",
    "if repair:\n",
    "    with open(os.path.join(gallery_base_path, \"gallery.json\")) as rf:\n",
    "        database = rf.readlines()\n",
    "\n",
    "    k = json.dumps(database[0].rsplit(\"\"\", {\"params\": \"\"\", 1)[0] + \"]\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataFrame(gallery_path = \"coupled_flux_qubit_protocol/coupled_flux_qubit_data_gallery/gallery.json\"):\n",
    "    df = pd.read_json(gallery_path)\n",
    "    df['comment'] = [item['comment'] for item in df[\"params\"]]\n",
    "    df[\"simulation_id\"] = [item[\"simulation_id\"] for item in df[\"simulation_data\"]]\n",
    "    return df\n",
    "\n",
    "df = loadDataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def process_date(date):\n",
    "    _date = \"2025-06-01 16:08:11.426624\"\n",
    "    _date = datetime.strptime(\"2025-06-01 16:08:1.426624\", \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    target_date = datetime.strptime(date, \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "    return _date < target_date \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = False\n",
    "\n",
    "if remove:\n",
    "\n",
    "    index = np.array([process_date(x['simulation_date']) for x in df[\"simulation_data\"].values])\n",
    "    target_sid = [item[\"simulation_id\"] for item in df[index]['simulation_data']]\n",
    "    os.system(\"rm -rf /Volumes/1TB/source/coupled_flux_qubit_protocol/coupled_flux_qubit_data_gallery\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_file_style = ['work_distribution.npy', 'work_statistic.npy', 'initial_index.npy', 'final_index.npy', 'final_state.npy', 'particle_index.npy', 'final_work_distribution.npy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sid in target_sid:\n",
    "    \n",
    "    for _style in saved_file_style:\n",
    "        \n",
    "        source_path = f\"/Users/tkwtang/source/coupled_flux_qubit_protocol/coupled_flux_qubit_data_gallery/{sid}_{_style}\"\n",
    "        destination_path = f\"/Volumes/1TB/source/coupled_flux_qubit_protocol/coupled_flux_qubit_data_gallery/{sid}_{_style}\"\n",
    "        if os.path.isfile(source_path):\n",
    "            shutil.copy2(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
